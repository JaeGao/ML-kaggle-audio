{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4080 Laptop GPU is available.\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Importing Libraries\n",
    "import random\n",
    "import tarfile\n",
    "import resampy\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import albumentations as A\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping extraction of train_mp3s.tar.\n",
      "Skipping extraction of test_mp3s.tar.\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Extracting Data\n",
    "def extract_tar(tar_file, target_dir):\n",
    "    if os.path.exists(target_dir):\n",
    "        user_input = input(f\"The directory '{target_dir}' already exists. Do you want to skip extraction? (y/n): \")\n",
    "        if user_input.lower() == 'y':\n",
    "            print(f\"Skipping extraction of {tar_file}.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Overwriting the existing directory '{target_dir}'.\")\n",
    "            shutil.rmtree(target_dir)\n",
    "    with tarfile.open(tar_file, 'r') as tar:\n",
    "        tar.extractall(target_dir)\n",
    "    # Remove residue \"._\" hidden files from the inner folder\n",
    "    inner_folder = os.path.join(target_dir, os.path.splitext(os.path.basename(tar_file))[0])\n",
    "    for root, dirs, files in os.walk(inner_folder):\n",
    "        for file in files:\n",
    "            if file.startswith(\"._\"):\n",
    "                os.remove(os.path.join(root, file))\n",
    "\n",
    "extract_tar('train_mp3s.tar', 'train_mp3s')\n",
    "extract_tar('test_mp3s.tar', 'test_mp3s')\n",
    "train_labels = np.loadtxt('train_label.txt', dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Preprocessing Functions\n",
    "def save_preprocessed_data(train_features, train_labels, test_features, folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    with open(os.path.join(folder_path, 'train_features.pkl'), 'wb') as f:\n",
    "        pickle.dump(train_features, f)\n",
    "\n",
    "    with open(os.path.join(folder_path, 'train_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(train_labels, f)\n",
    "\n",
    "    with open(os.path.join(folder_path, 'test_features.pkl'), 'wb') as f:\n",
    "        pickle.dump(test_features, f)\n",
    "\n",
    "def load_preprocessed_data(folder_path):\n",
    "    with open(os.path.join(folder_path, 'train_features.pkl'), 'rb') as f:\n",
    "        train_features = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(folder_path, 'train_labels.pkl'), 'rb') as f:\n",
    "        train_labels = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(folder_path, 'test_features.pkl'), 'rb') as f:\n",
    "        test_features = pickle.load(f)\n",
    "\n",
    "    return train_features, train_labels, test_features\n",
    "\n",
    "def extract_mfcc(audio, sample_rate):\n",
    "    return librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "def extract_mel_spec(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128)\n",
    "    return mel_spec\n",
    "\n",
    "def extract_tonnetz(audio, sample_rate):\n",
    "    return librosa.feature.tonnetz(y=audio, sr=sample_rate)\n",
    "\n",
    "def extract_chroma_stft(audio, sample_rate):\n",
    "    return librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "\n",
    "def extract_chroma_cqt(audio, sample_rate):\n",
    "    return librosa.feature.chroma_cqt(y=audio, sr=sample_rate)\n",
    "\n",
    "def extract_chroma_cens(audio, sample_rate):\n",
    "    return librosa.feature.chroma_cens(y=audio, sr=sample_rate)\n",
    "\n",
    "def apply_specmix(mel_spec, label, train_features, train_labels, num_mixes=2, alpha=0.2):\n",
    "    # Get the indices of samples with the same label\n",
    "    same_label_indices = np.where(train_labels == label)[0]\n",
    "\n",
    "    if len(same_label_indices) < num_mixes:\n",
    "        # If there are not enough samples with the same label, use all available samples\n",
    "        mix_indices = same_label_indices\n",
    "    else:\n",
    "        # Randomly select num_mixes samples with the same label\n",
    "        mix_indices = np.random.choice(same_label_indices, size=num_mixes, replace=False)\n",
    "\n",
    "    # Get the mel spectrograms of the selected samples\n",
    "    mix_mel_specs = train_features[mix_indices]\n",
    "\n",
    "    # Generate mixing weights using the Beta distribution\n",
    "    weights = np.random.beta(alpha, alpha, size=len(mix_indices))\n",
    "    weights_norm = weights / np.sum(weights)\n",
    "\n",
    "    # Truncate or pad the selected mel spectrograms to match the shape of the input mel spectrogram\n",
    "    target_length = mel_spec.shape[1]\n",
    "    mix_mel_specs_resized = []\n",
    "    for spec in mix_mel_specs:\n",
    "        if len(spec.shape) == 1:\n",
    "            # If spec is 1-dimensional, reshape it to 2-dimensional\n",
    "            spec = spec.reshape(1, -1)\n",
    "        if spec.shape[1] > target_length:\n",
    "            # Truncate the spectrogram if it is longer than the target length\n",
    "            spec = spec[:, :target_length]\n",
    "        elif spec.shape[1] < target_length:\n",
    "            # Pad the spectrogram with zeros if it is shorter than the target length\n",
    "            pad_width = target_length - spec.shape[1]\n",
    "            spec = np.pad(spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        mix_mel_specs_resized.append(spec)\n",
    "\n",
    "    # Mix the mel spectrograms using the generated weights\n",
    "    mixed_mel_spec = np.zeros_like(mel_spec)\n",
    "    for i in range(len(mix_indices)):\n",
    "        mixed_mel_spec += weights_norm[i] * mix_mel_specs_resized[i]\n",
    "\n",
    "    return mixed_mel_spec\n",
    "\n",
    "def apply_audio_augmentation(mel_spec, label, train_features, train_labels):\n",
    "    augmented_mel_spec = apply_specmix(mel_spec, label, train_features, train_labels)\n",
    "    return augmented_mel_spec\n",
    "\n",
    "def preprocess_audio(file_path, label, train_features, train_labels, augment=False):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        print(f\"Loaded audio file: {file_path}\")\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=128)\n",
    "\n",
    "        if augment and label is not None and train_features is not None and train_labels is not None:\n",
    "            augmented_mel_spec = apply_audio_augmentation(mel_spec, label, train_features, train_labels)\n",
    "            features_scaled = np.mean(augmented_mel_spec.T, axis=0)\n",
    "        else:\n",
    "            features_scaled = np.mean(mel_spec.T, axis=0)\n",
    "\n",
    "        print(f\"Extracted features: {features_scaled.shape}\")\n",
    "        return features_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file_path}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_file(file_path, label, train_features, train_labels, augment=False):\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    if label is None:\n",
    "        # If label is None, pass None for train_features and train_labels as well\n",
    "        features = preprocess_audio(file_path, None, None, None, augment=augment)\n",
    "    else:\n",
    "        features = preprocess_audio(file_path, label, train_features, train_labels, augment=augment)\n",
    "    return features\n",
    "\n",
    "def prepare_data(directory, train_features, train_labels, augment=False):\n",
    "    file_paths = [os.path.join(directory, f\"{i}.mp3\") for i in range(len(os.listdir(directory)))]\n",
    "    labels = train_labels.tolist() if train_labels is not None else [None] * len(file_paths)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        results = list(executor.map(lambda x: process_file(x[0], x[1], train_features, train_labels, augment), zip(file_paths, labels)))\n",
    "    \n",
    "    features = [feat for feat in results if feat is not None]\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"No audio files were successfully processed.\")\n",
    "    \n",
    "    features = np.array(features)\n",
    "    print(f\"Processed {len(features)} audio files\")\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data from the 'V6' folder.\n",
      "(2447, 1, 128)\n",
      "(23772, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "# Block 4: Preparing Data (modified)\n",
    "folder_path = 'V6'\n",
    "\n",
    "try:\n",
    "    train_features, train_labels, test_features = load_preprocessed_data(folder_path)\n",
    "    print(\"Loaded preprocessed data from the 'V6' folder.\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "    train_features_original = prepare_data('train_mp3s/train_mp3s', np.empty((0, 128)), train_labels_encoded)\n",
    "    print(f\"Original train features shape: {train_features_original.shape}\")\n",
    "\n",
    "    train_features_augmented = prepare_data('train_mp3s/train_mp3s', train_features_original, train_labels_encoded, augment=True)\n",
    "    print(f\"Augmented train features shape: {train_features_augmented.shape}\")\n",
    "\n",
    "    train_features = np.concatenate((train_features_original, train_features_augmented), axis=0)\n",
    "    print(f\"Combined train features shape: {train_features.shape}\")\n",
    "\n",
    "    test_features = prepare_data('test_mp3s/test_mp3s', np.empty((0, 128)), None)\n",
    "    print(f\"Test features shape: {test_features.shape}\")\n",
    "\n",
    "    train_labels_augmented = train_labels_encoded.copy()\n",
    "    train_labels_encoded = np.concatenate((train_labels_encoded, train_labels_augmented), axis=0)\n",
    "    print(f\"Train labels shape: {train_labels_encoded.shape}\")\n",
    "\n",
    "    print(f\"Number of training features: {len(train_features)}\")\n",
    "    print(f\"Number of training labels: {len(train_labels_encoded)}\")\n",
    "    print(f\"Number of test features: {len(test_features)}\")\n",
    "\n",
    "    save_preprocessed_data(train_features, train_labels_encoded, test_features, folder_path)\n",
    "    print(f\"Saved preprocessed data to the {folder_path} folder.\")\n",
    "\n",
    "if len(train_features) == 0:\n",
    "    print(\"No training features available. Please check the data.\")\n",
    "\n",
    "# Reshape the features to have a channel dimension of 1\n",
    "train_features = train_features.reshape(-1, 1, train_features.shape[1])\n",
    "test_features = test_features.reshape(-1, 1, test_features.shape[1])\n",
    "print(test_features.shape)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mojii\\anaconda3\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mojii\\anaconda3\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\mojii/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.1605, Train Accuracy: 0.4701, Val Loss: 1.1980, Val Accuracy: 0.4759\n",
      "Epoch [2/50], Train Loss: 1.1686, Train Accuracy: 0.4554, Val Loss: 1.1736, Val Accuracy: 0.4624\n",
      "Epoch [3/50], Train Loss: 1.3202, Train Accuracy: 0.4409, Val Loss: 1.3314, Val Accuracy: 0.4435\n",
      "Epoch [4/50], Train Loss: 1.0326, Train Accuracy: 0.5201, Val Loss: 1.0740, Val Accuracy: 0.5035\n",
      "Epoch [5/50], Train Loss: 1.0268, Train Accuracy: 0.5207, Val Loss: 1.0777, Val Accuracy: 0.5034\n",
      "Epoch [6/50], Train Loss: 1.0106, Train Accuracy: 0.5262, Val Loss: 1.0856, Val Accuracy: 0.4826\n",
      "Epoch [7/50], Train Loss: 0.8872, Train Accuracy: 0.5885, Val Loss: 0.9803, Val Accuracy: 0.5610\n",
      "Epoch [8/50], Train Loss: 1.0216, Train Accuracy: 0.5130, Val Loss: 1.1374, Val Accuracy: 0.4802\n",
      "Epoch [9/50], Train Loss: 0.9053, Train Accuracy: 0.6035, Val Loss: 1.0493, Val Accuracy: 0.5552\n",
      "Epoch [10/50], Train Loss: 0.8475, Train Accuracy: 0.6072, Val Loss: 1.0216, Val Accuracy: 0.5499\n",
      "Epoch [11/50], Train Loss: 0.8297, Train Accuracy: 0.6167, Val Loss: 1.0323, Val Accuracy: 0.5578\n",
      "Epoch [12/50], Train Loss: 0.8331, Train Accuracy: 0.6080, Val Loss: 1.0266, Val Accuracy: 0.5301\n",
      "Epoch [13/50], Train Loss: 1.2058, Train Accuracy: 0.5058, Val Loss: 1.4390, Val Accuracy: 0.4771\n",
      "Epoch [14/50], Train Loss: 0.8991, Train Accuracy: 0.5792, Val Loss: 1.1229, Val Accuracy: 0.4958\n",
      "Epoch [15/50], Train Loss: 0.8370, Train Accuracy: 0.6084, Val Loss: 1.1185, Val Accuracy: 0.5398\n",
      "Epoch [16/50], Train Loss: 0.7406, Train Accuracy: 0.6422, Val Loss: 1.0261, Val Accuracy: 0.5559\n",
      "Epoch [17/50], Train Loss: 0.7679, Train Accuracy: 0.6379, Val Loss: 1.0738, Val Accuracy: 0.5517\n",
      "Epoch [18/50], Train Loss: 0.8114, Train Accuracy: 0.6269, Val Loss: 1.1779, Val Accuracy: 0.5562\n",
      "Epoch [19/50], Train Loss: 0.8704, Train Accuracy: 0.6120, Val Loss: 1.2798, Val Accuracy: 0.5383\n",
      "Epoch [20/50], Train Loss: 0.7738, Train Accuracy: 0.6377, Val Loss: 1.1598, Val Accuracy: 0.5602\n",
      "Epoch [21/50], Train Loss: 0.7679, Train Accuracy: 0.6406, Val Loss: 1.1093, Val Accuracy: 0.5600\n",
      "Epoch [22/50], Train Loss: 0.6901, Train Accuracy: 0.6696, Val Loss: 1.0616, Val Accuracy: 0.5791\n",
      "Epoch [23/50], Train Loss: 0.7280, Train Accuracy: 0.6674, Val Loss: 1.1496, Val Accuracy: 0.5787\n",
      "Epoch [24/50], Train Loss: 0.7313, Train Accuracy: 0.6522, Val Loss: 1.1618, Val Accuracy: 0.5635\n",
      "Epoch [25/50], Train Loss: 0.8330, Train Accuracy: 0.6127, Val Loss: 1.1562, Val Accuracy: 0.5346\n",
      "Epoch [26/50], Train Loss: 0.6759, Train Accuracy: 0.6736, Val Loss: 1.0836, Val Accuracy: 0.5848\n",
      "Epoch [27/50], Train Loss: 0.6983, Train Accuracy: 0.6636, Val Loss: 1.0904, Val Accuracy: 0.5815\n",
      "Epoch [28/50], Train Loss: 0.7966, Train Accuracy: 0.6350, Val Loss: 1.2574, Val Accuracy: 0.5585\n",
      "Epoch [29/50], Train Loss: 0.6986, Train Accuracy: 0.6668, Val Loss: 1.2109, Val Accuracy: 0.5662\n",
      "Epoch [30/50], Train Loss: 0.8770, Train Accuracy: 0.6046, Val Loss: 1.3159, Val Accuracy: 0.5247\n",
      "Epoch [31/50], Train Loss: 0.7046, Train Accuracy: 0.6668, Val Loss: 1.1816, Val Accuracy: 0.5670\n",
      "Epoch [32/50], Train Loss: 0.7004, Train Accuracy: 0.6677, Val Loss: 1.1312, Val Accuracy: 0.5792\n",
      "Epoch [33/50], Train Loss: 0.6574, Train Accuracy: 0.6800, Val Loss: 1.1094, Val Accuracy: 0.5932\n",
      "Epoch [34/50], Train Loss: 0.7128, Train Accuracy: 0.6633, Val Loss: 1.2330, Val Accuracy: 0.5759\n",
      "Epoch [35/50], Train Loss: 0.7092, Train Accuracy: 0.6678, Val Loss: 1.2651, Val Accuracy: 0.5817\n",
      "Epoch [36/50], Train Loss: 0.7206, Train Accuracy: 0.6593, Val Loss: 1.2074, Val Accuracy: 0.5752\n",
      "Epoch [37/50], Train Loss: 0.7032, Train Accuracy: 0.6617, Val Loss: 1.2182, Val Accuracy: 0.5602\n",
      "Epoch [38/50], Train Loss: 0.6770, Train Accuracy: 0.6736, Val Loss: 1.2751, Val Accuracy: 0.5843\n",
      "Epoch [39/50], Train Loss: 0.6939, Train Accuracy: 0.6694, Val Loss: 1.2322, Val Accuracy: 0.5722\n",
      "Epoch [40/50], Train Loss: 0.6549, Train Accuracy: 0.6793, Val Loss: 1.0705, Val Accuracy: 0.5892\n",
      "Epoch [41/50], Train Loss: 0.6645, Train Accuracy: 0.6779, Val Loss: 1.0935, Val Accuracy: 0.5895\n",
      "Epoch [42/50], Train Loss: 0.6613, Train Accuracy: 0.6791, Val Loss: 1.0996, Val Accuracy: 0.5896\n",
      "Epoch [43/50], Train Loss: 1.0576, Train Accuracy: 0.5984, Val Loss: 1.7893, Val Accuracy: 0.5158\n",
      "Epoch [44/50], Train Loss: 0.7004, Train Accuracy: 0.6763, Val Loss: 1.2926, Val Accuracy: 0.5808\n",
      "Epoch [45/50], Train Loss: 0.8141, Train Accuracy: 0.6278, Val Loss: 1.3699, Val Accuracy: 0.5334\n",
      "Epoch [46/50], Train Loss: 0.7287, Train Accuracy: 0.6528, Val Loss: 1.2821, Val Accuracy: 0.5582\n",
      "Epoch [47/50], Train Loss: 0.6539, Train Accuracy: 0.6829, Val Loss: 1.1900, Val Accuracy: 0.5944\n",
      "Epoch [48/50], Train Loss: 0.6497, Train Accuracy: 0.6837, Val Loss: 1.1684, Val Accuracy: 0.5909\n",
      "Epoch [49/50], Train Loss: 0.6887, Train Accuracy: 0.6682, Val Loss: 1.2003, Val Accuracy: 0.5693\n",
      "Epoch [50/50], Train Loss: 0.6646, Train Accuracy: 0.6778, Val Loss: 1.2381, Val Accuracy: 0.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mojii\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Block 5: Model Training and Prediction\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if len(train_features) > 0:\n",
    "    if len(train_features) != len(train_labels):\n",
    "        raise ValueError(\"Number of train features and labels do not match.\")\n",
    "\n",
    "    # Normalize the input data\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, 128)).reshape(-1, 1, 128)\n",
    "    test_features = scaler.transform(test_features.reshape(-1, 128)).reshape(-1, 1, 128)\n",
    "\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(train_features, train_labels, test_size=0.3, random_state=42)\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32, device=device)\n",
    "    val_data = torch.tensor(val_data, dtype=torch.float32, device=device)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.long, device=device)\n",
    "    val_labels = torch.tensor(val_labels, dtype=torch.long, device=device)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(128, 2048),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(2048, 1024),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 4)\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 1000\n",
    "    batch_size = 1024\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data = batch_data.squeeze(1)  # Remove the extra dimension\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_data = train_data.squeeze(1)  # Remove the extra dimension\n",
    "            train_outputs = model(train_data)\n",
    "            train_loss = criterion(train_outputs, train_labels)\n",
    "            _, train_predicted = torch.max(train_outputs, 1)\n",
    "            train_accuracy = (train_predicted == train_labels).float().mean()\n",
    "\n",
    "            val_data = val_data.squeeze(1)  # Remove the extra dimension\n",
    "            val_outputs = model(val_data)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_accuracy = (val_predicted == val_labels).float().mean()\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Train Accuracy: {train_accuracy.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy.item():.4f}\")\n",
    "\n",
    "    test_features = torch.tensor(test_features, dtype=torch.float32, device=device)\n",
    "    test_features = test_features.squeeze(1)  # Remove the extra dimension\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_features)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        predicted_labels = predicted_labels.cpu().tolist()\n",
    "\n",
    "    submission = pd.DataFrame({'id': range(len(predicted_labels)), 'category': predicted_labels})\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "else:\n",
    "    print(\"No training features available. Please check the data.\")\n",
    "model.cpu()  # Move the model to CPU\n",
    "torch.cuda.empty_cache()  # Clear GPU memory cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
